{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\GitHub\\Retinal_Diseases_Classifier\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu118'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import engine\n",
    "import helper_functions\n",
    "import utils\n",
    "import data_setup\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directory paths to train and test images\n",
    "train_dir = \"data/Train/DISEASE\"\n",
    "val_dir = \"data/Val/DISEASE\"\n",
    "test_dir = \"data/Test/DISEASE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetb2, effnetb2_transforms = engine.create_pretrained_effnet_model(version=\"b2\", num_classes=4,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARMD', 'DR', 'MH', 'ODC']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader_effnetb2, test_dataloader_effnetb2, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                                                 test_dir=test_dir,\n",
    "                                                                                                 transforms=effnetb2_transforms,\n",
    "                                                                                                 batch_size=32)\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 31\n",
      "Dataset size: 961\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total batches: {len(train_dataloader_effnetb2)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader_effnetb2.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train EffnetB2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:42<02:49, 42.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss : 1.0270 | train_acc : 0.6290 | train_prec : 0.0000 | train_rec : 0.0000 | train_f1 : 0.0000 | test_loss : 1.1040 | test_acc : 0.5920 | test_prec : 0.0000 | test_rec : 0.0000 | test_f1 : 0.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:34<02:24, 48.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss : 1.0180 | train_acc : 0.6835 | train_prec : 0.0000 | train_rec : 0.0000 | train_f1 : 0.0000 | test_loss : 0.7732 | test_acc : 0.7139 | test_prec : 0.0000 | test_rec : 0.0000 | test_f1 : 0.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:21<01:35, 47.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss : 0.6387 | train_acc : 0.7863 | train_prec : 0.0000 | train_rec : 0.0000 | train_f1 : 0.0000 | test_loss : 0.5501 | test_acc : 0.7979 | test_prec : 0.0000 | test_rec : 0.0000 | test_f1 : 0.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:11<00:48, 48.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss : 0.4561 | train_acc : 0.8387 | train_prec : 0.0000 | train_rec : 0.0000 | train_f1 : 0.0000 | test_loss : 0.9937 | test_acc : 0.6684 | test_prec : 0.0000 | test_rec : 0.0000 | test_f1 : 0.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:56<00:00, 47.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss : 0.4785 | train_acc : 0.8347 | train_prec : 0.0000 | train_rec : 0.0000 | train_f1 : 0.0000 | test_loss : 0.4988 | test_acc : 0.8174 | test_prec : 0.0000 | test_rec : 0.0000 | test_f1 : 0.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.AdamW(params=effnetb2.parameters(),lr=0.003, weight_decay=1e-5)\n",
    "\n",
    "# Setup loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "effnetb2.to(device)\n",
    "# Set seeds for reproducibility and train the model\n",
    "helper_functions.set_seeds()\n",
    "effnetb2_results = engine.train(model=effnetb2,\n",
    "                                train_dataloader=train_dataloader_effnetb2,\n",
    "                                test_dataloader=test_dataloader_effnetb2,\n",
    "                                epochs=5,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                device=device,\n",
    "                                binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models\\pretrained_effnetb2_type_classification.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "utils.save_model(model=effnetb2,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"pretrained_effnetb2_type_classification.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained EffNetB2 feature extractor model size: 29 MB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get the model size in bytes then convert to megabytes\n",
    "pretrained_effnetb2_model_size = Path(\"models/pretrained_effnetb2_type_classification.pth\").stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) \n",
    "print(f\"Pretrained EffNetB2 feature extractor model size: {pretrained_effnetb2_model_size} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4987876519560814,\n",
       " 'test_acc': 0.8173611111111111,\n",
       " 'number_of_parameters': 7706630,\n",
       " 'model_size (MB)': 29}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of parameters in EffNetB2\n",
    "effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())\n",
    "\n",
    "# Create a dictionary with EffNetB2 statistics\n",
    "effnetb2_stats = {\"test_loss\": effnetb2_results[\"test_loss\"][-1],\n",
    "                  \"test_acc\": effnetb2_results[\"test_acc\"][-1],\n",
    "                  \"number_of_parameters\": effnetb2_total_params,\n",
    "                  \"model_size (MB)\": pretrained_effnetb2_model_size}\n",
    "effnetb2_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding all filepaths ending with '.jpg' in directory: data/Test/DISEASE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/Test/DISEASE/ARMD/DatasetA_110.png'),\n",
       " WindowsPath('data/Test/DISEASE/ARMD/DatasetA_12.png'),\n",
       " WindowsPath('data/Test/DISEASE/ARMD/DatasetA_122.png'),\n",
       " WindowsPath('data/Test/DISEASE/ARMD/DatasetA_152.png'),\n",
       " WindowsPath('data/Test/DISEASE/ARMD/DatasetA_188.png')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}\")\n",
    "test_data_paths = list(Path(test_dir).glob(\"*/*.png\"))\n",
    "test_data_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to make predictions and store results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions with effnetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306/306 [00:58<00:00,  5.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions across test dataset with EffNetB2\n",
    "import predict\n",
    "effnetb2_test_pred_dicts = predict.pred_and_store(paths=test_data_paths,\n",
    "                                          model=effnetb2,\n",
    "                                          transform=effnetb2_transforms,\n",
    "                                          class_names=class_names,\n",
    "                                          device=\"cpu\") # make predictions on CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_path': WindowsPath('data/Test/DISEASE/ARMD/DatasetA_110.png'),\n",
       "  'class_name': 'ARMD',\n",
       "  'pred_prob': 0.8835,\n",
       "  'pred_class': 'ARMD',\n",
       "  'time_for_pred': 1.2328,\n",
       "  'correct': True},\n",
       " {'image_path': WindowsPath('data/Test/DISEASE/ARMD/DatasetA_12.png'),\n",
       "  'class_name': 'ARMD',\n",
       "  'pred_prob': 0.5127,\n",
       "  'pred_class': 'DR',\n",
       "  'time_for_pred': 0.2829,\n",
       "  'correct': False}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnetb2_test_pred_dicts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pandas Dataframe to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_name</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>time_for_pred</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data\\Test\\DISEASE\\ARMD\\DatasetA_110.png</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>1.2328</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\Test\\DISEASE\\ARMD\\DatasetA_12.png</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data\\Test\\DISEASE\\ARMD\\DatasetA_122.png</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>0.5137</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data\\Test\\DISEASE\\ARMD\\DatasetA_152.png</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>DR</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data\\Test\\DISEASE\\ARMD\\DatasetA_188.png</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>ARMD</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                image_path class_name  pred_prob pred_class  \\\n",
       "0  data\\Test\\DISEASE\\ARMD\\DatasetA_110.png       ARMD     0.8835       ARMD   \n",
       "1   data\\Test\\DISEASE\\ARMD\\DatasetA_12.png       ARMD     0.5127         DR   \n",
       "2  data\\Test\\DISEASE\\ARMD\\DatasetA_122.png       ARMD     0.5137       ARMD   \n",
       "3  data\\Test\\DISEASE\\ARMD\\DatasetA_152.png       ARMD     0.9939         DR   \n",
       "4  data\\Test\\DISEASE\\ARMD\\DatasetA_188.png       ARMD     0.5720       ARMD   \n",
       "\n",
       "   time_for_pred  correct  \n",
       "0         1.2328     True  \n",
       "1         0.2829    False  \n",
       "2         0.2444     True  \n",
       "3         0.1636    False  \n",
       "4         0.1823     True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the test_pred_dicts into a DataFrame\n",
    "import pandas as pd\n",
    "effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred_dicts)\n",
    "effnetb2_test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct\n",
       "True     252\n",
       "False     54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnetb2_test_pred_df.correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EffNetB2 average time per prediction: 0.1896 seconds\n"
     ]
    }
   ],
   "source": [
    "effnetb2_average_time_per_pred = round(effnetb2_test_pred_df.time_for_pred.mean(), 4)\n",
    "print(f\"EffNetB2 average time per prediction: {effnetb2_average_time_per_pred} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio version: 5.21.0\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "print(f\"Gradio version: {gr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs -> ML model -> outputs  \n",
    "input: image -> transform -> predict with EffNetB2 -> output: pred, pred prob, time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put EffNetB2 on CPU\n",
    "effnetb2.to(\"cpu\") \n",
    "\n",
    "# Check the device\n",
    "next(iter(effnetb2.parameters())).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "def predict(img) -> Tuple[Dict, float]:\n",
    "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
    "    \"\"\"\n",
    "    start_time = timer()\n",
    "    \n",
    "    # transform image and add batch dim\n",
    "    img = effnetb2_transforms(img).unsqueeze(0)\n",
    "    \n",
    "    # put model in eval mode and turn on inference mode\n",
    "    effnetb2.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred_probs = torch.softmax(effnetb2(img), dim = 1)\n",
    "        \n",
    "    # create prediction label and prediction prob\n",
    "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
    "    \n",
    "    pred_time = round(timer() - start_time, 5)\n",
    "    \n",
    "    return pred_labels_and_probs, pred_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting on image at path: data\\pizza_steak_sushi_20_percent\\test\\steak\\289822.jpg\n",
      "\n",
      "Prediction label and probability dictionary: \n",
      "{'pizza': 0.004519496578723192, 'steak': 0.9843215942382812, 'sushi': 0.011158893816173077}\n",
      "Prediction time: 0.06489 seconds\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Randomly select a test image path\n",
    "random_image_path = random.sample(test_data_paths, k=1)[0]\n",
    "\n",
    "# open image\n",
    "image = Image.open(random_image_path)\n",
    "print(f\"[INFO] Predicting on image at path: {random_image_path}\\n\")\n",
    "\n",
    "# Predict on the target image and print out the outputs\n",
    "pred_dict, pred_time = predict(img=image)\n",
    "print(f\"Prediction label and probability dictionary: \\n{pred_dict}\")\n",
    "print(f\"Prediction time: {pred_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['data\\\\pizza_steak_sushi_20_percent\\\\test\\\\sushi\\\\2352914.jpg'],\n",
       " ['data\\\\pizza_steak_sushi_20_percent\\\\test\\\\sushi\\\\472912.jpg'],\n",
       " ['data\\\\pizza_steak_sushi_20_percent\\\\test\\\\pizza\\\\724290.jpg']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of example inputs to our Gradio demo\n",
    "example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]\n",
    "example_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create title, description and article strings\n",
    "title = \"FoodVision Mini 🍕🥩🍣\"\n",
    "description = \"An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi.\"\n",
    "article = \"Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio demo\n",
    "demo = gr.Interface(fn=predict, # mapping function from input to output\n",
    "                    inputs=gr.Image(type=\"pil\"), # what are the inputs?\n",
    "                    outputs=[gr.Label(num_top_classes=3, label=\"Predictions\"), # what are the outputs?\n",
    "                             gr.Number(label=\"Prediction time (s)\")], # our fn has two outputs, therefore we have two outputs\n",
    "                    examples=example_list, \n",
    "                    title=title,\n",
    "                    description=description,\n",
    "                    article=article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the demo!\n",
    "#demo.launch(debug=False, # print errors locally?\n",
    "#           share=True) # generate a publically shareable URL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Demo Directory to deploy on Hugging Face Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create FoodVision mini demo path\n",
    "foodvision_mini_demo_path = Path(\"demos/foodvision_mini/\")\n",
    "\n",
    "# Remove files that might already exist there and create new directory\n",
    "if foodvision_mini_demo_path.exists():\n",
    "    shutil.rmtree(foodvision_mini_demo_path)\n",
    "# If the file doesn't exist, create it anyway\n",
    "foodvision_mini_demo_path.mkdir(parents=True, \n",
    "                                exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Copying data\\pizza_steak_sushi_20_percent\\test\\sushi\\592799.jpg to demos\\foodvision_mini\\examples\\592799.jpg\n",
      "[INFO] Copying data\\pizza_steak_sushi_20_percent\\test\\steak\\3622237.jpg to demos\\foodvision_mini\\examples\\3622237.jpg\n",
      "[INFO] Copying data\\pizza_steak_sushi_20_percent\\test\\pizza\\2582289.jpg to demos\\foodvision_mini\\examples\\2582289.jpg\n"
     ]
    }
   ],
   "source": [
    "# 1. Create an examples directory\n",
    "foodvision_mini_examples_path = foodvision_mini_demo_path / \"examples\"\n",
    "foodvision_mini_examples_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Collect three random test dataset image paths\n",
    "foodvision_mini_examples = [Path('data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg'),\n",
    "                            Path('data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg'),\n",
    "                            Path('data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg')]\n",
    "\n",
    "# 3. Copy the three random images to the examples directory\n",
    "for example in foodvision_mini_examples:\n",
    "    destination = foodvision_mini_examples_path / example.name\n",
    "    print(f\"[INFO] Copying {example} to {destination}\")\n",
    "    shutil.copy2(src=example, dst=destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['examples/2582289.jpg'], ['examples/3622237.jpg'], ['examples/592799.jpg']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get example filepaths in a list of lists\n",
    "example_list = [[\"examples/\" + example] for example in os.listdir(foodvision_mini_examples_path)]\n",
    "example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Attempting to move models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth to demos\\foodvision_mini\\09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth\n",
      "[INFO] No model found at models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth, perhaps its already been moved?\n",
      "[INFO] Model exists at demos\\foodvision_mini\\09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth: True\n"
     ]
    }
   ],
   "source": [
    "# Create a source path for our target model\n",
    "effnetb2_foodvision_mini_model_path = \"models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth\"\n",
    "\n",
    "# Create a destination path for our target model \n",
    "effnetb2_foodvision_mini_model_destination = foodvision_mini_demo_path / effnetb2_foodvision_mini_model_path.split(\"/\")[1]\n",
    "\n",
    "# Try to move the file\n",
    "try:\n",
    "    print(f\"[INFO] Attempting to move {effnetb2_foodvision_mini_model_path} to {effnetb2_foodvision_mini_model_destination}\")\n",
    "    \n",
    "    # Move the model\n",
    "    shutil.move(src=effnetb2_foodvision_mini_model_path, \n",
    "                dst=effnetb2_foodvision_mini_model_destination)\n",
    "    \n",
    "    print(f\"[INFO] Model move complete.\")\n",
    "\n",
    "# If the model has already been moved, check if it exists\n",
    "except:\n",
    "    print(f\"[INFO] No model found at {effnetb2_foodvision_mini_model_path}, perhaps its already been moved?\")\n",
    "    print(f\"[INFO] Model exists at {effnetb2_foodvision_mini_model_destination}: {effnetb2_foodvision_mini_model_destination.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Compress-Archive' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
