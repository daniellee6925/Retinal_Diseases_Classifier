{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cu118'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import engine\n",
    "import helper_functions\n",
    "import utils\n",
    "import data_setup\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directory paths to train and test images\n",
    "train_dir = \"data/Train\"\n",
    "val_dir = \"data/Val\"\n",
    "test_dir = \"data/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetb1, effnetb1_transforms = engine.create_pretrained_effnet_model(version=\"b1\", num_classes=1,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DISEASE', 'NORMAL']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader_effnetb1, test_dataloader_effnetb1, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                                                 test_dir=test_dir,\n",
    "                                                                                                 transforms=effnetb1_transforms,\n",
    "                                                                                                 batch_size=32)\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 43\n",
      "Dataset size: 1362\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total batches: {len(train_dataloader_effnetb1)}\")\n",
    "print(f\"Dataset size: {len(train_dataloader_effnetb1.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom collections import Counter\\n\\n# Assuming you have a DataLoader `train_loader` and your dataset is labeled\\ndef count_classes(dataloader):\\n    class_counts = Counter()\\n\\n    for _, labels in dataloader:\\n        # If labels are one-hot encoded, get the class index by using argmax\\n        if labels.ndimension() > 1:\\n            labels = labels.argmax(dim=1)\\n\\n        # Update class counts\\n        class_counts.update(labels.numpy())\\n\\n    return class_counts\\n\\nclass_counts = count_classes(test_dataloader_effnetb2)\\nprint(class_counts)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have a DataLoader `train_loader` and your dataset is labeled\n",
    "def count_classes(dataloader):\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    for _, labels in dataloader:\n",
    "        # If labels are one-hot encoded, get the class index by using argmax\n",
    "        if labels.ndimension() > 1:\n",
    "            labels = labels.argmax(dim=1)\n",
    "        \n",
    "        # Update class counts\n",
    "        class_counts.update(labels.numpy())\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "class_counts = count_classes(test_dataloader_effnetb2)\n",
    "print(class_counts)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train EffnetB2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 1/5 [00:43<02:52, 43.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss : 0.4318 | train_acc : 0.8165 | train_prec : 0.9223 | train_rec : 0.7968 | train_f1 : 0.8413 | test_loss : 0.2467 | test_acc : 0.9129 | test_prec : 0.6905 | test_rec : 0.6379 | test_f1 : 0.6606 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [01:28<02:13, 44.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss : 0.3081 | train_acc : 0.8755 | train_prec : 0.9654 | train_rec : 0.8571 | train_f1 : 0.9048 | test_loss : 0.2273 | test_acc : 0.9152 | test_prec : 0.7013 | test_rec : 0.6205 | test_f1 : 0.6543 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [02:18<01:33, 46.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss : 0.3178 | train_acc : 0.8602 | train_prec : 0.9619 | train_rec : 0.8421 | train_f1 : 0.8930 | test_loss : 0.2449 | test_acc : 0.8996 | test_prec : 0.7013 | test_rec : 0.6071 | test_f1 : 0.6460 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [03:05<00:47, 47.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss : 0.2306 | train_acc : 0.9048 | train_prec : 0.9728 | train_rec : 0.8904 | train_f1 : 0.9285 | test_loss : 0.3254 | test_acc : 0.9040 | test_prec : 0.7013 | test_rec : 0.6071 | test_f1 : 0.6465 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [03:56<00:00, 47.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss : 0.2137 | train_acc : 0.9038 | train_prec : 0.9720 | train_rec : 0.8922 | train_f1 : 0.9276 | test_loss : 0.2510 | test_acc : 0.9070 | test_prec : 0.6905 | test_rec : 0.6446 | test_f1 : 0.6657 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup optimizer\n",
    "optimizer = torch.optim.AdamW(params=effnetb1.parameters(),lr=0.003, weight_decay=1e-5)\n",
    "\n",
    "weight_class_0 = 1 / (961 / (961 + 401))  # Inverse of class 0 frequency\n",
    "weight_class_1 = 1 / (401 / (961 + 401))  # Inverse of class 1 frequency\n",
    "class_weights = torch.tensor([weight_class_0, weight_class_1]).to(device)\n",
    "# Setup loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights[0])\n",
    "\n",
    "\n",
    "effnetb1.to(device)\n",
    "# Set seeds for reproducibility and train the model\n",
    "helper_functions.set_seeds()\n",
    "effnetb2_results = engine.train(model=effnetb1,\n",
    "                                train_dataloader=train_dataloader_effnetb1,\n",
    "                                test_dataloader=test_dataloader_effnetb1,\n",
    "                                epochs=5,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                device=device,\n",
    "                                binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models\\pretrained_effnetb0_disease_classification.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "utils.save_model(model=effnetb1,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"pretrained_effnetb0_disease_classification.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained EffNetB1 model size: 25 MB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get the model size in bytes then convert to megabytes\n",
    "pretrained_effnetb1_model_size = Path(\"models/pretrained_effnetb0_disease_classification.pth\").stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) \n",
    "print(f\"Pretrained EffNetB1 model size: {pretrained_effnetb1_model_size} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.25098785598363194,\n",
       " 'test_acc': 0.9069940476190476,\n",
       " 'number_of_parameters': 6514465,\n",
       " 'model_size (MB)': 25}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of parameters in EffNetB2\n",
    "effnetb1_total_params = sum(torch.numel(param) for param in effnetb1.parameters())\n",
    "\n",
    "# Create a dictionary with EffNetB2 statistics\n",
    "effnetb1_stats = {\"test_loss\": effnetb2_results[\"test_loss\"][-1],\n",
    "                  \"test_acc\": effnetb2_results[\"test_acc\"][-1],\n",
    "                  \"number_of_parameters\": effnetb1_total_params,\n",
    "                  \"model_size (MB)\": pretrained_effnetb1_model_size}\n",
    "effnetb1_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finding all filepaths ending with '.jpg' in directory: data/Test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/Test/NORMAL/DatasetA_245.png'),\n",
       " WindowsPath('data/Test/NORMAL/DatasetA_272.png'),\n",
       " WindowsPath('data/Test/NORMAL/DatasetA_273.png'),\n",
       " WindowsPath('data/Test/NORMAL/DatasetA_276.png'),\n",
       " WindowsPath('data/Test/NORMAL/DatasetA_277.png')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}\")\n",
    "test_data_paths = list(Path(test_dir).glob(\"*/*.png\"))\n",
    "test_data_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to make predictions and store results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions with effnetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134/134 [00:34<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions across test dataset with EffNetB2\n",
    "import predict\n",
    "effnetb2_test_pred_dicts = predict.pred_and_store(paths=test_data_paths,\n",
    "                                          model=effnetb1,\n",
    "                                          transform=effnetb1_transforms,\n",
    "                                          class_names=class_names,\n",
    "                                          device=\"cpu\") # make predictions on CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_path': WindowsPath('data/Test/NORMAL/DatasetA_245.png'),\n",
       "  'class_name': 'NORMAL',\n",
       "  'pred_prob': 1.0,\n",
       "  'pred_class': 'DISEASE',\n",
       "  'time_for_pred': 1.033,\n",
       "  'correct': False},\n",
       " {'image_path': WindowsPath('data/Test/NORMAL/DatasetA_272.png'),\n",
       "  'class_name': 'NORMAL',\n",
       "  'pred_prob': 1.0,\n",
       "  'pred_class': 'DISEASE',\n",
       "  'time_for_pred': 0.1067,\n",
       "  'correct': False}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnetb2_test_pred_dicts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pandas Dataframe to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_name</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>time_for_pred</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data\\Test\\NORMAL\\DatasetA_245.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>1.0330</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data\\Test\\NORMAL\\DatasetA_272.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data\\Test\\NORMAL\\DatasetA_273.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data\\Test\\NORMAL\\DatasetA_276.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data\\Test\\NORMAL\\DatasetA_277.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image_path class_name  pred_prob pred_class  \\\n",
       "0  data\\Test\\NORMAL\\DatasetA_245.png     NORMAL        1.0    DISEASE   \n",
       "1  data\\Test\\NORMAL\\DatasetA_272.png     NORMAL        1.0    DISEASE   \n",
       "2  data\\Test\\NORMAL\\DatasetA_273.png     NORMAL        1.0    DISEASE   \n",
       "3  data\\Test\\NORMAL\\DatasetA_276.png     NORMAL        1.0    DISEASE   \n",
       "4  data\\Test\\NORMAL\\DatasetA_277.png     NORMAL        1.0    DISEASE   \n",
       "\n",
       "   time_for_pred  correct  \n",
       "0         1.0330    False  \n",
       "1         0.1067    False  \n",
       "2         0.0928    False  \n",
       "3         0.0824    False  \n",
       "4         0.0950    False  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the test_pred_dicts into a DataFrame\n",
    "import pandas as pd\n",
    "effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred_dicts)\n",
    "effnetb2_test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct\n",
       "False    134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnetb2_test_pred_df.correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EffNetB2 average time per prediction: 0.0453 seconds\n"
     ]
    }
   ],
   "source": [
    "effnetb2_average_time_per_pred = round(effnetb2_test_pred_df.time_for_pred.mean(), 4)\n",
    "print(f\"EffNetB2 average time per prediction: {effnetb2_average_time_per_pred} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio version: 5.21.0\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "print(f\"Gradio version: {gr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs -> ML model -> outputs  \n",
    "input: image -> transform -> predict with EffNetB2 -> output: pred, pred prob, time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put EffNetB2 on CPU\n",
    "effnetb2.to(\"cpu\") \n",
    "\n",
    "# Check the device\n",
    "next(iter(effnetb2.parameters())).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "def predict(img) -> Tuple[Dict, float]:\n",
    "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
    "    \"\"\"\n",
    "    start_time = timer()\n",
    "    \n",
    "    # transform image and add batch dim\n",
    "    img = effnetb2_transforms(img).unsqueeze(0)\n",
    "    \n",
    "    # put model in eval mode and turn on inference mode\n",
    "    effnetb2.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred_probs = torch.softmax(effnetb2(img), dim = 1)\n",
    "        \n",
    "    # create prediction label and prediction prob\n",
    "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
    "    \n",
    "    pred_time = round(timer() - start_time, 5)\n",
    "    \n",
    "    return pred_labels_and_probs, pred_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting on image at path: data\\pizza_steak_sushi_20_percent\\test\\steak\\289822.jpg\n",
      "\n",
      "Prediction label and probability dictionary: \n",
      "{'pizza': 0.004519496578723192, 'steak': 0.9843215942382812, 'sushi': 0.011158893816173077}\n",
      "Prediction time: 0.06489 seconds\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Randomly select a test image path\n",
    "random_image_path = random.sample(test_data_paths, k=1)[0]\n",
    "\n",
    "# open image\n",
    "image = Image.open(random_image_path)\n",
    "print(f\"[INFO] Predicting on image at path: {random_image_path}\\n\")\n",
    "\n",
    "# Predict on the target image and print out the outputs\n",
    "pred_dict, pred_time = predict(img=image)\n",
    "print(f\"Prediction label and probability dictionary: \\n{pred_dict}\")\n",
    "print(f\"Prediction time: {pred_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['data\\\\pizza_steak_sushi_20_percent\\\\test\\\\sushi\\\\2352914.jpg'],\n",
       " ['data\\\\pizza_steak_sushi_20_percent\\\\test\\\\sushi\\\\472912.jpg'],\n",
       " ['data\\\\pizza_steak_sushi_20_percent\\\\test\\\\pizza\\\\724290.jpg']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of example inputs to our Gradio demo\n",
    "example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]\n",
    "example_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create title, description and article strings\n",
    "title = \"FoodVision Mini üçïü•©üç£\"\n",
    "description = \"An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi.\"\n",
    "article = \"Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio demo\n",
    "demo = gr.Interface(fn=predict, # mapping function from input to output\n",
    "                    inputs=gr.Image(type=\"pil\"), # what are the inputs?\n",
    "                    outputs=[gr.Label(num_top_classes=3, label=\"Predictions\"), # what are the outputs?\n",
    "                             gr.Number(label=\"Prediction time (s)\")], # our fn has two outputs, therefore we have two outputs\n",
    "                    examples=example_list, \n",
    "                    title=title,\n",
    "                    description=description,\n",
    "                    article=article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the demo!\n",
    "#demo.launch(debug=False, # print errors locally?\n",
    "#           share=True) # generate a publically shareable URL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Demo Directory to deploy on Hugging Face Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create FoodVision mini demo path\n",
    "foodvision_mini_demo_path = Path(\"demos/foodvision_mini/\")\n",
    "\n",
    "# Remove files that might already exist there and create new directory\n",
    "if foodvision_mini_demo_path.exists():\n",
    "    shutil.rmtree(foodvision_mini_demo_path)\n",
    "# If the file doesn't exist, create it anyway\n",
    "foodvision_mini_demo_path.mkdir(parents=True, \n",
    "                                exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Copying data\\pizza_steak_sushi_20_percent\\test\\sushi\\592799.jpg to demos\\foodvision_mini\\examples\\592799.jpg\n",
      "[INFO] Copying data\\pizza_steak_sushi_20_percent\\test\\steak\\3622237.jpg to demos\\foodvision_mini\\examples\\3622237.jpg\n",
      "[INFO] Copying data\\pizza_steak_sushi_20_percent\\test\\pizza\\2582289.jpg to demos\\foodvision_mini\\examples\\2582289.jpg\n"
     ]
    }
   ],
   "source": [
    "# 1. Create an examples directory\n",
    "foodvision_mini_examples_path = foodvision_mini_demo_path / \"examples\"\n",
    "foodvision_mini_examples_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Collect three random test dataset image paths\n",
    "foodvision_mini_examples = [Path('data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg'),\n",
    "                            Path('data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg'),\n",
    "                            Path('data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg')]\n",
    "\n",
    "# 3. Copy the three random images to the examples directory\n",
    "for example in foodvision_mini_examples:\n",
    "    destination = foodvision_mini_examples_path / example.name\n",
    "    print(f\"[INFO] Copying {example} to {destination}\")\n",
    "    shutil.copy2(src=example, dst=destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['examples/2582289.jpg'], ['examples/3622237.jpg'], ['examples/592799.jpg']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get example filepaths in a list of lists\n",
    "example_list = [[\"examples/\" + example] for example in os.listdir(foodvision_mini_examples_path)]\n",
    "example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Attempting to move models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth to demos\\foodvision_mini\\09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth\n",
      "[INFO] No model found at models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth, perhaps its already been moved?\n",
      "[INFO] Model exists at demos\\foodvision_mini\\09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth: True\n"
     ]
    }
   ],
   "source": [
    "# Create a source path for our target model\n",
    "effnetb2_foodvision_mini_model_path = \"models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth\"\n",
    "\n",
    "# Create a destination path for our target model \n",
    "effnetb2_foodvision_mini_model_destination = foodvision_mini_demo_path / effnetb2_foodvision_mini_model_path.split(\"/\")[1]\n",
    "\n",
    "# Try to move the file\n",
    "try:\n",
    "    print(f\"[INFO] Attempting to move {effnetb2_foodvision_mini_model_path} to {effnetb2_foodvision_mini_model_destination}\")\n",
    "    \n",
    "    # Move the model\n",
    "    shutil.move(src=effnetb2_foodvision_mini_model_path, \n",
    "                dst=effnetb2_foodvision_mini_model_destination)\n",
    "    \n",
    "    print(f\"[INFO] Model move complete.\")\n",
    "\n",
    "# If the model has already been moved, check if it exists\n",
    "except:\n",
    "    print(f\"[INFO] No model found at {effnetb2_foodvision_mini_model_path}, perhaps its already been moved?\")\n",
    "    print(f\"[INFO] Model exists at {effnetb2_foodvision_mini_model_destination}: {effnetb2_foodvision_mini_model_destination.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Compress-Archive' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
